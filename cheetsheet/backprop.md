(backprop)=
# Бэкпроп

Бэкпроп это техника, которая используется в машинном обучении, но, в рудиментарном виде, ей можно пользоваться при разнообразных вычислениях.

Типичной является ситуация, когда вас просят сосчитать градиент некоторой функции, например, косвенной полезности или функции расходов. Представьте себе, что вы уже умеете находить $\nabla V$ в какой то спецификации, но из-за монотонного преобразования полезности вас теперь просят найти $\nabla \log V$ или $\nabla \exp(V)$.

Вместо того, чтобы вычислять всю функцию заново, вы можете взять уже известный вам градиент $\nabla V$ и "протащить его" через внешнее монотонное преобразование, как если бы градиент был числом:

$$ \nabla \log(V) = \frac{\nabla V}{V}, \quad \nabla \exp(V) = \exp(V) \nabla V$$

В общем случае, когда преобразование векторзначное, перемножения становятся матричными, и это называется бэкпроп. В частном случае, когда преобразование скалярное, можно пользоваться правилами классического дифференциирования.

Этой техникой удобно пользоваться при работе с Кобб-Дуглас.